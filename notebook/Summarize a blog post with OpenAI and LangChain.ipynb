{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **How to create a tweet from one of my blog posts using LangChain and Azure OpenAI**\n",
    "\n",
    "- This notebook shows how you can create the content for a tweet from a given blog post URI.\n",
    "- It uses LangChain and Azure OpenAi to summarize the entire blog post in a 200 word tweet.\n",
    "\n",
    "## **What is LangChain?** \n",
    "\n",
    "[LangChain](https://python.langchain.com/en/latest/index.html) is a framework for interacting with Large Language Models (LLMs). It provides a helpful abstraction for the most common LLM design patterns:\n",
    "\n",
    "- Pre-processing the corpus (input data) by iterating over some documents.\n",
    "- Splitting the documents into chunks.\n",
    "- Summarizing them.\n",
    "- Embedding the document chunks in a vector data source.\n",
    "- When a question is asked, searches the vector data source for similar document chunks.\n",
    "- Passes these chunks to the LLM, along with the question, to get an answer in response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Import dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Configure Azure OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://{BASE}.openai.azure.com\"\n",
    "API_KEY = \"PUT-YOUR-API-KEY-HERE\"\n",
    "DEPLOYMENT_NAME = \"PUT-YOUR-DEPLOYMENT-NAME-HERE\"\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_base=BASE_URL,\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_type = \"azure\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Read the content of a blog post from a given URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.mytechramblings.com/posts/how-to-integrate-your-roslyn-analyzers-with-sonarqube/'\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=[\n",
    "    url\n",
    "])\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Split the entire post into chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "\n",
    "texts = text_splitter.split_documents(data)\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Use the LangChain 'map-reduce' chain to geneate the tweet content**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are the author of the source text.\n",
    "You need to write a tweet that summarizes the source text.\n",
    "The tweet must not contain any kind of code.\n",
    "Make sure the tweet is compelling and well-written. \n",
    "The tweet must end with the following phrase: 'More details in: www.mytechramblings.com'\n",
    "The total tweet size must have no more than 270 characters.\n",
    "\n",
    "SOURCE:\n",
    "{text}\n",
    "\n",
    "TWEET IN ENGLISH:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", combine_prompt=prompt)\n",
    "chain.run(texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
